# Génération de Dockerfile avec IA

## Objectif

Créer des Dockerfiles optimisés, sécurisés et respectant les bonnes pratiques pour containeriser des applications, en exploitant l'IA pour générer du code de qualité production.

## Contexte entreprise

Une équipe DevOps d'une startup tech doit containeriser plusieurs applications legacy pour migration vers Kubernetes :
- Application web Node.js (React frontend)
- API REST Python (Flask)
- Service background Java (Spring Boot)
- Base de données PostgreSQL (pour dev/test)

Contraintes :
- Images Docker légères (< 500 MB si possible)
- Sécurité renforcée (pas de root, scanning vulnerabilities)
- Build reproductibles (versions fixes)
- Multi-stage builds pour optimisation

Créer manuellement des Dockerfiles optimisés demande une expertise Docker avancée et du temps de recherche des bonnes pratiques.

## Problème

Créer un Dockerfile production-ready implique :
- Choisir la bonne image de base
- Optimiser les layers pour le cache
- Gérer les dépendances correctement
- Minimiser la taille de l'image
- Appliquer les bonnes pratiques de sécurité
- Configurer le healthcheck
- Documenter le build

**Temps estimé** : 1-3 heures pour un Dockerfile optimisé selon l'application

**Difficultés** :
- Multitude de choix d'images de base
- Optimisations non évidentes (multi-stage, layer caching)
- Bonnes pratiques de sécurité méconnues

## Solution traditionnelle

### Méthode manuelle

1. Rechercher des exemples de Dockerfile pour le stack technologique
2. Copier un exemple basique
3. Adapter à l'application
4. Builder et tester
5. Optimiser itérativement (taille, sécurité)
6. Lire la documentation Docker best practices
7. Appliquer les recommandations

### Limites

- Processus d'essai-erreur long
- Risque de Dockerfile non optimisé (taille excessive)
- Failles de sécurité (root user, images vulnérables)
- Manque de reproductibilité (latest tags)

## Apport de l'IA

L'IA permet de :
- Générer un Dockerfile complet avec multi-stage build
- Appliquer automatiquement les bonnes pratiques (non-root user, healthcheck)
- Optimiser la taille (alpine images, suppression des caches)
- Documenter le Dockerfile avec commentaires clairs
- Adapter aux contraintes spécifiques (CI/CD, Kubernetes)

**Temps avec IA** : 15-30 minutes (génération + adaptation + tests)

**Gain de productivité** : 70-80%

## Mise en œuvre étape par étape

### Étape 1 : Analyser l'application à containeriser

Identifier :
- Stack technique (langage, framework, versions)
- Dépendances système nécessaires
- Port d'écoute de l'application
- Commande de démarrage
- Variables d'environnement requises
- Besoins de build (compilation, minification)

**Exemple : Application Node.js/React**
```
Stack : Node.js 18, React 18, npm
Build : npm install + npm run build
Runtime : npm start (port 3000)
Env vars : NODE_ENV, API_URL
```

### Étape 2 : Rédiger un prompt structuré

**Prompt efficace** :

```
Génère un Dockerfile optimisé pour une application Node.js/React.

**Contexte :**
- Frontend React (build statique servi par Node.js Express)
- Node.js version 18
- Port d'écoute : 3000
- Variables d'environnement : NODE_ENV, API_URL

**Structure de l'application :**
```
/app
├── package.json
├── package-lock.json
├── src/
│   ├── App.js
│   └── ...
├── public/
└── server.js  (Express server pour servir le build)
```

**Exigences :**
1. Multi-stage build :
   - Stage 1 : Build de l'app React
   - Stage 2 : Image runtime légère
2. Image de base : Alpine Linux (légèreté)
3. User non-root pour sécurité
4. Versions fixes (pas de 'latest')
5. Optimisation du cache Docker (layer ordering)
6. Healthcheck sur /health endpoint
7. Nettoyage des caches npm
8. Exposition du port 3000
9. Labels pour metadata (version, maintainer)

**Commandes de build attendues :**
```bash
npm ci  # Installation déterministe
npm run build  # Build production React
```

**Commande de démarrage :**
```bash
node server.js
```

Format : Dockerfile commenté, prêt à l'emploi, respectant les best practices Docker.
```

### Étape 3 : Générer le Dockerfile avec l'IA

**Exemple de Dockerfile généré** :

```dockerfile
# ============================================
# Stage 1: Build de l'application React
# ============================================
FROM node:18-alpine AS builder

# Métadonnées
LABEL maintainer="devops@entreprise.com"
LABEL version="1.0.0"
LABEL description="Application React containerisée"

# Définir le répertoire de travail
WORKDIR /app

# Copier les fichiers de dépendances en premier (cache Docker)
COPY package.json package-lock.json ./

# Installation des dépendances (npm ci pour reproductibilité)
RUN npm ci --only=production \
    && npm cache clean --force

# Copier le code source
COPY . .

# Build de l'application React
RUN npm run build

# ============================================
# Stage 2: Image runtime optimisée
# ============================================
FROM node:18-alpine AS runtime

# Variables d'environnement par défaut
ENV NODE_ENV=production \
    PORT=3000

# Créer un utilisateur non-root pour sécurité
RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser

# Définir le répertoire de travail
WORKDIR /app

# Copier uniquement les fichiers nécessaires depuis le stage builder
COPY --from=builder --chown=appuser:appgroup /app/build ./build
COPY --from=builder --chown=appuser:appgroup /app/node_modules ./node_modules
COPY --from=builder --chown=appuser:appgroup /app/server.js ./
COPY --from=builder --chown=appuser:appgroup /app/package.json ./

# Changer vers l'utilisateur non-root
USER appuser

# Exposer le port
EXPOSE 3000

# Healthcheck (vérifie toutes les 30s que l'app répond)
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
    CMD node -e "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

# Commande de démarrage
CMD ["node", "server.js"]
```

### Étape 4 : Adapter et tester

#### Créer un .dockerignore

```
# .dockerignore
node_modules
npm-debug.log
.git
.gitignore
.dockerignore
Dockerfile
.env
.env.local
README.md
.vscode
.idea
build
dist
coverage
```

#### Builder l'image

```bash
docker build -t mon-app-react:1.0.0 .
```

#### Vérifier la taille

```bash
docker images mon-app-react:1.0.0
# Attendu : < 200 MB pour Node + React
```

#### Tester l'image

```bash
docker run -d -p 3000:3000 \
  -e NODE_ENV=production \
  -e API_URL=https://api.exemple.com \
  --name mon-app-test \
  mon-app-react:1.0.0

# Vérifier les logs
docker logs mon-app-test

# Tester l'accès
curl http://localhost:3000/health

# Vérifier que l'utilisateur n'est pas root
docker exec mon-app-test whoami
# Doit afficher : appuser

# Arrêter et supprimer
docker stop mon-app-test && docker rm mon-app-test
```

### Étape 5 : Scanner pour les vulnérabilités

```bash
# Avec Docker Desktop
docker scan mon-app-react:1.0.0

# Avec Trivy (outil open-source)
trivy image mon-app-react:1.0.0
```

Corriger les vulnérabilités identifiées (mise à jour des dépendances, changement d'image de base).

### Étape 6 : Optimiser davantage si nécessaire

Demander à l'IA :

```
Le Dockerfile fonctionne mais l'image fait 250 MB. Comment l'optimiser davantage ?

Pistes :
- Utiliser une image encore plus légère ?
- Supprimer des fichiers inutiles ?
- Optimiser les layers ?
```

### Étape 7 : Documenter et versionner

Créer un README.md :

```markdown
# Docker image - Application React

## Build

```bash
docker build -t entreprise/mon-app-react:1.0.0 .
```

## Run

```bash
docker run -d -p 3000:3000 \
  -e NODE_ENV=production \
  -e API_URL=https://api.exemple.com \
  entreprise/mon-app-react:1.0.0
```

## Variables d'environnement

- `NODE_ENV` : production | development (défaut: production)
- `API_URL` : URL de l'API backend
- `PORT` : Port d'écoute (défaut: 3000)

## Healthcheck

Endpoint : `GET /health`
Doit retourner 200 OK

## Versions

- Node.js : 18-alpine
- React : 18
- Taille image : ~180 MB
```

Versionner dans Git avec le code de l'application.

## Scripts / Commandes / Configurations

### Exemple de Dockerfile pour API Python/Flask

Prompt :

```
Génère un Dockerfile optimisé pour une API REST Python Flask.

Contexte :
- Python 3.11
- Flask 3.0
- Port : 5000
- Dépendances : requirements.txt
- Base de données : PostgreSQL (client psycopg2)

Exigences :
- Multi-stage build
- Image Alpine
- User non-root
- Gunicorn pour production (4 workers)
- Healthcheck sur /api/health
- Versions fixes
```

**Dockerfile généré** :

```dockerfile
# Stage 1: Builder
FROM python:3.11-alpine AS builder

WORKDIR /app

# Installer les dépendances de compilation (pour psycopg2)
RUN apk add --no-cache gcc musl-dev postgresql-dev

# Copier requirements et installer
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-alpine

ENV PYTHONUNBUFFERED=1 \
    FLASK_ENV=production \
    GUNICORN_WORKERS=4

# Installer uniquement les libs runtime (pas gcc)
RUN apk add --no-cache libpq

# Créer user non-root
RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser

WORKDIR /app

# Copier les dépendances Python depuis builder
COPY --from=builder --chown=appuser:appgroup /root/.local /home/appuser/.local

# Copier le code de l'application
COPY --chown=appuser:appgroup . .

# Ajouter .local/bin au PATH
ENV PATH=/home/appuser/.local/bin:$PATH

USER appuser

EXPOSE 5000

HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:5000/api/health')"

CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "app:app"]
```

### Dockerfile pour application Java Spring Boot

```dockerfile
# Stage 1: Build avec Maven
FROM maven:3.9-eclipse-temurin-17-alpine AS builder

WORKDIR /app

# Copier pom.xml pour cache des dépendances
COPY pom.xml .
RUN mvn dependency:go-offline

# Copier le code source et builder
COPY src ./src
RUN mvn clean package -DskipTests

# Stage 2: Runtime
FROM eclipse-temurin:17-jre-alpine

ENV JAVA_OPTS="-Xmx512m -Xms256m"

RUN addgroup -g 1001 appgroup && \
    adduser -D -u 1001 -G appgroup appuser

WORKDIR /app

# Copier le JAR depuis le builder
COPY --from=builder --chown=appuser:appgroup /app/target/*.jar app.jar

USER appuser

EXPOSE 8080

HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### Script de build et push automatisé

```bash
#!/bin/bash
# build-and-push.sh
# Build Docker image et push vers registry

set -e

APP_NAME="mon-app-react"
VERSION=$(git describe --tags --always)
REGISTRY="registry.entreprise.com"

echo "=== Build Docker Image ==="
docker build -t ${APP_NAME}:${VERSION} .
docker tag ${APP_NAME}:${VERSION} ${APP_NAME}:latest

echo "=== Scan de sécurité ==="
trivy image ${APP_NAME}:${VERSION}

echo "=== Tag pour registry ==="
docker tag ${APP_NAME}:${VERSION} ${REGISTRY}/${APP_NAME}:${VERSION}
docker tag ${APP_NAME}:latest ${REGISTRY}/${APP_NAME}:latest

echo "=== Push vers registry ==="
docker push ${REGISTRY}/${APP_NAME}:${VERSION}
docker push ${REGISTRY}/${APP_NAME}:latest

echo "✓ Image pushed : ${REGISTRY}/${APP_NAME}:${VERSION}"
```

### Docker Compose pour développement

```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - API_URL=http://localhost:5000/api
    volumes:
      - ./src:/app/src  # Hot reload en dev
    depends_on:
      - postgres

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: apppass
      POSTGRES_DB: appdb
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

## Risques et limites

### Risques de sécurité

**Images avec vulnérabilités** : Même avec Alpine, des vulnérabilités peuvent exister. Toujours scanner avec Trivy ou Snyk.

**Secrets dans l'image** : Ne jamais inclure de secrets (API keys, passwords) dans le Dockerfile. Utiliser des secrets Kubernetes ou Docker secrets.

### Limites de l'IA

**Contexte spécifique** : L'IA génère du code standard. Des besoins très spécifiques (drivers spéciaux, configs complexes) nécessitent adaptation.

**Versions des dépendances** : L'IA peut suggérer des versions pas à jour. Toujours vérifier les dernières versions stables.

### Risques opérationnels

**Image trop grosse** : Une image de plusieurs GB ralentit les déploiements. Toujours viser < 500 MB si possible.

**Dépendances système manquantes** : Des libs système peuvent manquer en runtime (ex: psycopg2 nécessite libpq).

## Bonnes pratiques

### Création du Dockerfile

1. Toujours utiliser multi-stage build pour optimisation
2. Fixer les versions (pas de `latest`)
3. Utiliser des images Alpine pour légèreté
4. Créer un user non-root
5. Optimiser l'ordre des layers (COPY package.json avant le code)
6. Ajouter un HEALTHCHECK
7. Nettoyer les caches (npm, apt, pip)
8. Documenter avec commentaires

### Tests

1. Builder localement et tester
2. Vérifier la taille de l'image (`docker images`)
3. Scanner pour vulnérabilités (Trivy, Snyk)
4. Tester le healthcheck fonctionne
5. Vérifier que l'utilisateur n'est pas root
6. Tester avec différentes variables d'environnement

### CI/CD

1. Automatiser le build dans CI (GitHub Actions, GitLab CI)
2. Scanner automatiquement chaque build
3. Bloquer le déploiement si vulnérabilités critiques
4. Versionner les images (tags Git)
5. Signer les images (Docker Content Trust)

### Maintenance

1. Mettre à jour régulièrement les images de base
2. Rescanner périodiquement les images déployées
3. Monitorer les CVE des dépendances
4. Documenter les changements (CHANGELOG)

## Ce que cela démontre à un recruteur

### Compétences techniques

- Maîtrise de Docker et des bonnes pratiques
- Connaissance multi-stack (Node.js, Python, Java)
- Compréhension de la sécurité des containers

### Approche DevOps

- Automatisation (scripts de build, CI/CD)
- Optimisation (taille images, layer caching)
- Sécurité (scanning, non-root, versions fixes)

### Efficacité

- Utilisation de l'IA pour accélérer sans sacrifier qualité
- Gain de temps de 70-80% sur création de Dockerfiles
- Code production-ready dès la première itération

### Rigueur

- Tests systématiques (build, scan, healthcheck)
- Documentation complète
- Versioning et traçabilité

**Message au recruteur** : Ce guide démontre un ingénieur DevOps capable de containeriser efficacement des applications en respectant les standards de l'industrie. L'utilisation de l'IA accélère la création de Dockerfiles optimisés, mais le professionnel valide, teste et sécurise chaque image, garantissant des déploiements fiables et sécurisés en production.
